{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "import requests\n",
    "import pandas as pd\n",
    "from datetime import datetime, timedelta\n",
    "import os\n",
    "import psycopg2\n",
    "from psycopg2 import extras\n",
    "from google.cloud import bigquery\n",
    "from google.cloud import storage\n",
    "from google.cloud.bigquery import SchemaField"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Boekr\\AppData\\Local\\Temp\\ipykernel_26904\\2735884802.py:29: FutureWarning: Passing bytes to 'read_excel' is deprecated and will be removed in a future version. To read from a byte string, wrap it in a `BytesIO` object.\n",
      "  modis_df = pd.read_excel(modis_data, sheet_name=\"ALL\")\n",
      "C:\\Users\\Boekr\\AppData\\Local\\Temp\\ipykernel_26904\\2735884802.py:31: FutureWarning: Passing bytes to 'read_excel' is deprecated and will be removed in a future version. To read from a byte string, wrap it in a `BytesIO` object.\n",
      "  viirs_df = pd.read_excel(viirs_data, sheet_name=\"ALL\")\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MODIS Excel file saved successfully at: GISTDA_Hotspot\\MODIS_20240604.xlsx\n",
      "VIIRS Excel file saved successfully at: GISTDA_Hotspot\\VIIRS_20240604.xlsx\n"
     ]
    }
   ],
   "source": [
    "# Download Excel files from fire GISTDA\n",
    "#https://fire.gistda.or.th/fire/y2024/80_Report/Excel/N_Mod_Day/N_Mod_20240422.xlsx\n",
    "#https://fire.gistda.or.th/fire/y2024/80_Report/Excel/N_Vi1_Day/N_Vi1_20240422.xlsx\n",
    "    \n",
    "\n",
    "base_url = \"https://fire.gistda.or.th/fire/y{}/80_Report/Excel/\"\n",
    "current_year = datetime.now().year\n",
    "date = datetime.now() - timedelta(days=1)\n",
    "date_str = date.strftime(\"%Y%m%d\")\n",
    "modis_url = base_url.format(current_year) + f\"N_Mod_Day/N_Mod_{date_str}.xlsx\" #on 06/06/2024 N_Mod_20240606.xlsx not found last file found is N_Mod_20240604.xlsx\n",
    "viirs_url = base_url.format(current_year) + f\"N_Vi1_Day/N_Vi1_{date_str}.xlsx\"\n",
    "\n",
    "\n",
    "#viirs_url = base_url.format(current_year) + f\"N_Vi1_Day/N_Vi1_20240422.xlsx\"\n",
    "#modis_url = base_url.format(current_year) + f\"N_Mod_Day/N_Mod_20240604.xlsx\"\n",
    "\n",
    "def download_excel(url):\n",
    "    response = requests.get(url)\n",
    "    if response.status_code == 200:\n",
    "        return response.content\n",
    "    else:\n",
    "        print(f\"Failed to download from {url}\")\n",
    "        return None\n",
    "\n",
    "modis_data = download_excel(modis_url) #on 06/06/2024 N_Mod_20240606.xlsx not found last file found is N_Mod_20240604.xlsx\n",
    "viirs_data = download_excel(viirs_url)\n",
    "\n",
    "if modis_data is None or viirs_data is None:\n",
    "    print(\"Exiting due to download failure\")\n",
    "    exit()\n",
    "\n",
    "modis_df = pd.read_excel(modis_data, sheet_name=\"ALL\")\n",
    "modis_df = modis_df.dropna(how='all')\n",
    "viirs_df = pd.read_excel(viirs_data, sheet_name=\"ALL\")\n",
    "viirs_df = viirs_df.dropna(how='all')\n",
    "\n",
    "# Filter out rows containing specific notes\n",
    "modis_df = modis_df[~modis_df['HotSpotID'].str.contains('หมายเหตุ', na=False)]\n",
    "modis_df = modis_df[~modis_df['HotSpotID'].str.contains('หมายเหตุ', na=False)]\n",
    "modis_df = modis_df[~modis_df['HotSpotID'].str.contains('ที่มาของข้อมูล', na=False)]\n",
    "modis_df = modis_df[~modis_df['HotSpotID'].str.contains('ข้อมูลจุดความร้อน', na=False)]\n",
    "modis_df = modis_df[~modis_df['HotSpotID'].str.contains('รายงานข้อมูลนี้จัดทำขึ้น', na=False)]\n",
    "modis_df = modis_df[~modis_df['HotSpotID'].str.contains('รายงานนี้เป็นรายงานสรุปเบื้องต้น', na=False)]\n",
    "modis_df = modis_df[~modis_df['HotSpotID'].str.contains('รายงานนี้เป็นรายงานสรุปเบื้องต้น ยังไม่สามารถอ้างอิงเป็นรายงานสุดท้ายได้', na=False)]\n",
    "modis_df = modis_df[~modis_df['HotSpotID'].str.contains('รายงานข้อมูลนี้จัดทำขึ้นเพื่อ การวางแผน และการเข้าระงับเหตุในพื้นที่', na=False)]\n",
    "\n",
    "viirs_df = viirs_df[~viirs_df['HotSpotID'].str.contains('หมายเหตุ', na=False)]\n",
    "viirs_df = viirs_df[~viirs_df['HotSpotID'].str.contains('หมายเหตุ', na=False)]\n",
    "viirs_df = viirs_df[~viirs_df['HotSpotID'].str.contains('ที่มาของข้อมูล', na=False)]\n",
    "viirs_df = viirs_df[~viirs_df['HotSpotID'].str.contains('ข้อมูลจุดความร้อน', na=False)]\n",
    "viirs_df = viirs_df[~viirs_df['HotSpotID'].str.contains('รายงานข้อมูลนี้จัดทำขึ้น', na=False)]\n",
    "viirs_df = viirs_df[~viirs_df['HotSpotID'].str.contains('รายงานนี้เป็นรายงานสรุปเบื้องต้น', na=False)]\n",
    "viirs_df = viirs_df[~viirs_df['HotSpotID'].str.contains('รายงานนี้เป็นรายงานสรุปเบื้องต้น ยังไม่สามารถอ้างอิงเป็นรายงานสุดท้ายได้', na=False)]\n",
    "viirs_df = viirs_df[~viirs_df['HotSpotID'].str.contains('รายงานข้อมูลนี้จัดทำขึ้นเพื่อ การวางแผน และการเข้าระงับเหตุในพื้นที่', na=False)]\n",
    "\n",
    "# Translate column headers to English\n",
    "# \"(\" , \")\", \".\" not allowed in column names for BigQuery change it to _\"\n",
    "translated_columns = {\n",
    "    \"วันที่\": \"Date\",\n",
    "    \"จังหวัด\": \"Province\",\n",
    "    \"อำเภอ\": \"District\",\n",
    "    \"ตำบล\": \"Subdistrict\",\n",
    "    \"ประเทศ\": \"Country\",\n",
    "    \"รหัสรับผิดชอบ\": \"Responsibility_Code\",\n",
    "    \"พื้นที่รับผิดชอบ\": \"Responsible_Area\",\n",
    "    \"รหัสการใช้ที่ดิน\": \"Land_Use_Code\",\n",
    "    \"การใช้ที่ดิน\": \"Land_Use\",\n",
    "    \"จุดใกล้หมู่บ้าน\": \"Near_Village_Point\",\n",
    "    \"ห่างหมู่บ้าน(กม)\": \"Distance_from_Village_km\",\n",
    "    \"องศาจากหมู่บ้าน\": \"Degree_from_Village\",\n",
    "    \"ทิศจากหมู่บ้าน\": \"Direction_from_Village\",\n",
    "    \"ตำบล.1\": \"Subdistrict_1\",\n",
    "    \"อำเภอ.1\": \"District_1\",\n",
    "    \"จังหวัด.1\": \"Province_1\",\n",
    "    \"วัน\": \"Day\",\n",
    "    \"เวลา\": \"Time\"\n",
    "}\n",
    "\n",
    "# Rename columns in MODIS DataFrame\n",
    "modis_df = modis_df.rename(columns=translated_columns)\n",
    "modis_df['Sensor'] = 'MODIS'\n",
    "\n",
    "# Rename columns in VIIRS DataFrame\n",
    "viirs_df = viirs_df.rename(columns=translated_columns)\n",
    "viirs_df['Sensor'] = 'VIIRS'\n",
    "\n",
    "# Define the folder to save the Excel files\n",
    "folder_name = \"GISTDA_Hotspot\"\n",
    "os.makedirs(folder_name, exist_ok=True)  # Create the folder if it doesn't exist\n",
    "\n",
    "# Save the MODIS DataFrame as an Excel file\n",
    "modis_filepath = os.path.join(folder_name, f\"MODIS_{date_str}.xlsx\")\n",
    "modis_df.to_excel(modis_filepath, index=False)\n",
    "print(f\"MODIS Excel file saved successfully at: {modis_filepath}\")\n",
    "\n",
    "# Save the VIIRS DataFrame as an Excel file\n",
    "viirs_filepath = os.path.join(folder_name, f\"VIIRS_{date_str}.xlsx\")\n",
    "viirs_df.to_excel(viirs_filepath, index=False)\n",
    "print(f\"VIIRS Excel file saved successfully at: {viirs_filepath}\")\n",
    "\n",
    "read_file = pd.read_excel(f\"GISTDA_Hotspot/MODIS_{date_str}.xlsx\")\n",
    "read_file.to_csv(f\"GISTDA_Hotspot/MODIS_{date_str}.csv\", index=False, header=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "File GISTDA_Hotspot/MODIS_20240604.csv uploaded to gistda/modis_gistda_hotspot/MODIS_20240604.csv.\n"
     ]
    }
   ],
   "source": [
    "os.environ['GOOGLE_APPLICATION_CREDENTIALS'] = r'envilink-1a0b1e56da79.json'\n",
    "def upload_file_to_gcs(bucket_name, source_file_name, destination_blob_name):\n",
    "    \"\"\"\n",
    "    Uploads a file to Google Cloud Storage.\n",
    "    \n",
    "    Args:\n",
    "    bucket_name: str. The name of the bucket.\n",
    "    source_file_name: str. The path to the file on local machine.\n",
    "    destination_blob_name: str. The destination path name within the GCS bucket.\n",
    "    \"\"\"\n",
    "    # Create a storage client\n",
    "    storage_client = storage.Client()\n",
    "    \n",
    "    # Get the bucket\n",
    "    bucket = storage_client.bucket(bucket_name)\n",
    "    \n",
    "    # Create a new blob and upload the file's content\n",
    "    blob = bucket.blob(destination_blob_name)\n",
    "    \n",
    "    # Upload the file\n",
    "    blob.upload_from_filename(source_file_name)\n",
    "    \n",
    "    print(f\"File {source_file_name} uploaded to {destination_blob_name}.\")\n",
    "\n",
    "# Example usage\n",
    "bucket_name = 'envilink_raw'  # Update this to your GCS bucket name\n",
    "source_file_name = f'GISTDA_Hotspot/MODIS_{date_str}.csv'  # Update this to the path of your local file\n",
    "destination_blob_name = f'gistda/modis_gistda_hotspot/MODIS_{date_str}.csv'  # Update this to the desired path in GCS\n",
    "upload_file_to_gcs(bucket_name, source_file_name, destination_blob_name)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Data from gs://envilink_raw/gistda/modis_gistda_hotspot/MODIS_20240604.csv has been successfully appended to envilink.gistda.MODIS_hotspot\n"
     ]
    }
   ],
   "source": [
    "PROJECT_ID = 'envilink'\n",
    "DATASET_NAME = 'gistda'\n",
    "TABLE_NAME = 'MODIS_hotspot'\n",
    "GCS_BUCKET = 'envilink_raw'\n",
    "GCS_FILE_PATH = f'gs://{GCS_BUCKET}/gistda/modis_gistda_hotspot/MODIS_{date_str}.csv'  # Update the filename as needed\n",
    "\n",
    "# Initialize the BigQuery client\n",
    "client = bigquery.Client(project=PROJECT_ID)\n",
    "\n",
    "def load_csv_to_bigquery(gcs_file_path, dataset_name, table_name):\n",
    "    # Construct the fully-qualified BigQuery table ID\n",
    "    table_id = f\"{PROJECT_ID}.{dataset_name}.{table_name}\"\n",
    "\n",
    "    # Set up the job configuration to append the data\n",
    "    job_config = bigquery.LoadJobConfig(\n",
    "        source_format=bigquery.SourceFormat.CSV,\n",
    "        skip_leading_rows=1,  # Assuming the first row is a header\n",
    "        autodetect=False,  # Automatically infer the schema\n",
    "        write_disposition=bigquery.WriteDisposition.WRITE_APPEND  # Append to the existing table\n",
    "    )\n",
    "\n",
    "    # Create a job to load the CSV data from GCS into the BigQuery table\n",
    "    load_job = client.load_table_from_uri(\n",
    "        gcs_file_path, \n",
    "        table_id, \n",
    "        job_config=job_config\n",
    "    )\n",
    "\n",
    "    # Wait for the job to complete\n",
    "    load_job.result()\n",
    "\n",
    "    # Check for errors\n",
    "    if load_job.errors:\n",
    "        print(\"Load job encountered the following errors:\", load_job.errors)\n",
    "    else:\n",
    "        print(f\"Data from {gcs_file_path} has been successfully appended to {table_id}\")\n",
    "\n",
    "# Run the function to load data\n",
    "load_csv_to_bigquery(GCS_FILE_PATH, DATASET_NAME, TABLE_NAME)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
